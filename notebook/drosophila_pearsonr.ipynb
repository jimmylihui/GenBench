{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "dest_path ='/liuzicheng/ljh/hyena-dna/data/drosophila_enhancer_activity'\n",
    "split='test'\n",
    "targets_file = os.path.join(dest_path, 'Sequences_activity_'+split+\".txt\")\n",
    "data = pd.read_csv(targets_file, sep=\"\\t\")[\n",
    "            [\"Dev_log2_enrichment\", \"Hk_log2_enrichment\"]\n",
    "        ]\n",
    "fasta_file= os.path.join(dest_path, 'Sequences_'+split+\".fa\")\n",
    "all_seqs = []\n",
    "all_labels = []\n",
    "\n",
    "with open(fasta_file) as fin:\n",
    "    header = False\n",
    "    for line in fin:\n",
    "        l = line.strip()\n",
    "        if len(l) == 0:  # last line\n",
    "            break\n",
    "        if line.startswith(\">\"):\n",
    "            header = True\n",
    "            continue\n",
    "        else:\n",
    "            assert header  # check fasta format is correct\n",
    "            all_seqs.append(l)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "all_labels=data[[\"Dev_log2_enrichment\", \"Hk_log2_enrichment\"]].values.astype(\"float32\").tolist()\n",
    "        \n",
    "assert len(all_seqs) == len(\n",
    "            all_labels\n",
    "        ), \"Number of targets does not match number of sequences\"\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "restrict = lambda x: (\n",
    "                    torch.cumsum(x, dim=-2)\n",
    "                    / torch.arange(\n",
    "                        1, 1 + x.size(-2), device=x.device, dtype=x.dtype\n",
    "                    ).unsqueeze(-1)\n",
    "                )[..., -1:, :]   \n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats\n",
    "def pearsonr_1(outs, y, len_batch=None):\n",
    "    # TODO: generalize, currently for Monash dataset\n",
    "    metrics = {}\n",
    "    outs=outs.detach()\n",
    "    for i, label in enumerate(['dev', 'hk']):\n",
    "        y_true = y[:, i].cpu().numpy()\n",
    "        p = outs[:, i].cpu().numpy()\n",
    "        r = stats.pearsonr(y_true, p)[0]\n",
    "        metrics[f'pearsonr_{label}'] = r\n",
    "        metrics[f'pearsonr2_{label}'] = r ** 2\n",
    "    metrics['pearsonr'] = (metrics['pearsonr_dev'] + metrics['pearsonr_hk']) / 2\n",
    "    return metrics\n",
    "import torch.nn.functional as F\n",
    "def mse(outs, y, len_batch=None):\n",
    "    # assert outs.shape[:-1] == y.shape and outs.shape[-1] == 1\n",
    "    # outs = outs.squeeze(-1)\n",
    "    # if len(y.shape) < len(outs.shape):\n",
    "    #     assert outs.shape[-1] == 1\n",
    "    #     outs = outs.squeeze(-1)\n",
    "    if len_batch is None:\n",
    "        # return F.mse_loss(outs, y)\n",
    "        loss = (\n",
    "                            (\n",
    "                                outs[~torch.isnan(y)]\n",
    "                                - y[~torch.isnan(y)]\n",
    "                            )\n",
    "                            ** 2\n",
    "                        ).mean()\n",
    "        #check if y include nan\n",
    "        if torch.isnan(outs).any():\n",
    "            nan_indices_outs=torch.nonzero(torch.isnan(outs), as_tuple=False)\n",
    "            print(nan_indices_outs)\n",
    "        \n",
    "        if torch.isnan(y).any():\n",
    "            nan_indices=torch.nonzero(torch.isnan(y), as_tuple=False)\n",
    "            print(nan_indices)\n",
    "        return loss\n",
    "    else:\n",
    "        # Computes the loss of the first `lens` items in the batches\n",
    "        # TODO document the use case of this\n",
    "        mask = torch.zeros_like(outs, dtype=torch.bool)\n",
    "        for i, l in enumerate(len_batch):\n",
    "            mask[i, :l, :] = 1\n",
    "        outs_masked = torch.masked_select(outs, mask)\n",
    "        y_masked = torch.masked_select(y, mask)\n",
    "        return F.mse_loss(outs_masked, y_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'pearsonr_dev': 0.28364549906781383, 'pearsonr2_dev': 0.08045476914142918, 'pearsonr_hk': 0.7182049665806906, 'pearsonr2_hk': 0.5158183740211708, 'pearsonr': 0.5009252328242522}\n",
      "2000\n",
      "{'pearsonr_dev': 0.2686941683903085, 'pearsonr2_dev': 0.07219655612695947, 'pearsonr_hk': 0.6727362950160191, 'pearsonr2_hk': 0.45257412263188024, 'pearsonr': 0.47071523170316376}\n",
      "3000\n",
      "{'pearsonr_dev': 0.44836453244429925, 'pearsonr2_dev': 0.20103075395399508, 'pearsonr_hk': 0.6601745122358464, 'pearsonr2_hk': 0.4358303866058378, 'pearsonr': 0.5542695223400729}\n",
      "4000\n",
      "{'pearsonr_dev': 0.4860841635844665, 'pearsonr2_dev': 0.23627781408761037, 'pearsonr_hk': 0.6544510277299389, 'pearsonr2_hk': 0.4283061476967733, 'pearsonr': 0.5702675956572028}\n",
      "5000\n",
      "{'pearsonr_dev': 0.4929511378143658, 'pearsonr2_dev': 0.24300082427247785, 'pearsonr_hk': 0.6431594390840369, 'pearsonr2_hk': 0.413654064082893, 'pearsonr': 0.5680552884492014}\n",
      "6000\n",
      "{'pearsonr_dev': 0.48780199029144755, 'pearsonr2_dev': 0.2379507817322975, 'pearsonr_hk': 0.6313691659917499, 'pearsonr2_hk': 0.39862702376511777, 'pearsonr': 0.5595855781415987}\n",
      "7000\n",
      "{'pearsonr_dev': 0.48971384195820244, 'pearsonr2_dev': 0.2398196470054633, 'pearsonr_hk': 0.6232653757515748, 'pearsonr2_hk': 0.38845972861075173, 'pearsonr': 0.5564896088548886}\n",
      "8000\n",
      "{'pearsonr_dev': 0.48635129043914005, 'pearsonr2_dev': 0.23653757771181677, 'pearsonr_hk': 0.6171600192854588, 'pearsonr2_hk': 0.38088648940442793, 'pearsonr': 0.5517556548622995}\n",
      "9000\n",
      "{'pearsonr_dev': 0.4813113105615146, 'pearsonr2_dev': 0.23166057767444276, 'pearsonr_hk': 0.6086690826542163, 'pearsonr2_hk': 0.37047805217912516, 'pearsonr': 0.5449901966078654}\n",
      "10000\n",
      "{'pearsonr_dev': 0.482951243317504, 'pearsonr2_dev': 0.23324190342192294, 'pearsonr_hk': 0.6033490302639875, 'pearsonr2_hk': 0.36403005232049407, 'pearsonr': 0.5431501367907458}\n",
      "11000\n",
      "{'pearsonr_dev': 0.48317834670959964, 'pearsonr2_dev': 0.23346131472902207, 'pearsonr_hk': 0.599915863752009, 'pearsonr2_hk': 0.359899043581319, 'pearsonr': 0.5415471052308043}\n",
      "12000\n",
      "{'pearsonr_dev': 0.48216785056456546, 'pearsonr2_dev': 0.23248583611805312, 'pearsonr_hk': 0.5937383121228598, 'pearsonr2_hk': 0.35252518328250243, 'pearsonr': 0.5379530813437126}\n",
      "13000\n",
      "{'pearsonr_dev': 0.48282159897007365, 'pearsonr2_dev': 0.23311669643201863, 'pearsonr_hk': 0.5825997901427277, 'pearsonr2_hk': 0.3394225154743503, 'pearsonr': 0.5327106945564006}\n",
      "14000\n",
      "{'pearsonr_dev': 0.47789051878679384, 'pearsonr2_dev': 0.22837934794631096, 'pearsonr_hk': 0.5745940022291258, 'pearsonr2_hk': 0.33015826739768467, 'pearsonr': 0.5262422605079599}\n",
      "15000\n",
      "{'pearsonr_dev': 0.48477787953723633, 'pearsonr2_dev': 0.23500959248861922, 'pearsonr_hk': 0.5739574270383101, 'pearsonr2_hk': 0.32942712805243707, 'pearsonr': 0.5293676532877732}\n",
      "16000\n",
      "{'pearsonr_dev': 0.4909965139989483, 'pearsonr2_dev': 0.24107757675911942, 'pearsonr_hk': 0.5735971912580917, 'pearsonr2_hk': 0.32901373781917187, 'pearsonr': 0.53229685262852}\n",
      "17000\n",
      "{'pearsonr_dev': 0.48894989102944286, 'pearsonr2_dev': 0.23907199593770406, 'pearsonr_hk': 0.5698011864759848, 'pearsonr2_hk': 0.32467339210943996, 'pearsonr': 0.5293755387527138}\n",
      "18000\n",
      "{'pearsonr_dev': 0.4841268842245547, 'pearsonr2_dev': 0.23437884002897538, 'pearsonr_hk': 0.5643594218228469, 'pearsonr2_hk': 0.3185015570002181, 'pearsonr': 0.5242431530237008}\n",
      "19000\n",
      "{'pearsonr_dev': 0.47902372918556585, 'pearsonr2_dev': 0.22946373312284632, 'pearsonr_hk': 0.5586255977888583, 'pearsonr2_hk': 0.31206255850495934, 'pearsonr': 0.5188246634872121}\n",
      "20000\n",
      "{'pearsonr_dev': 0.47343371617827296, 'pearsonr2_dev': 0.2241394836143695, 'pearsonr_hk': 0.552450607653973, 'pearsonr2_hk': 0.30520167389724406, 'pearsonr': 0.512942161916123}\n",
      "21000\n",
      "{'pearsonr_dev': 0.4805773782264929, 'pearsonr2_dev': 0.2309546164630496, 'pearsonr_hk': 0.5598867757050926, 'pearsonr2_hk': 0.31347320160944464, 'pearsonr': 0.5202320769657928}\n",
      "22000\n",
      "{'pearsonr_dev': 0.5029530621908977, 'pearsonr2_dev': 0.25296178276720105, 'pearsonr_hk': 0.5843462943660099, 'pearsonr2_hk': 0.34146059173928756, 'pearsonr': 0.5436496782784539}\n",
      "23000\n",
      "{'pearsonr_dev': 0.5029947736752474, 'pearsonr2_dev': 0.2530037423446133, 'pearsonr_hk': 0.5988401359408312, 'pearsonr2_hk': 0.35860950841363315, 'pearsonr': 0.5509174548080393}\n",
      "24000\n",
      "{'pearsonr_dev': 0.4998023850571914, 'pearsonr2_dev': 0.249802424108857, 'pearsonr_hk': 0.595168262658735, 'pearsonr2_hk': 0.354225260876217, 'pearsonr': 0.5474853238579632}\n",
      "25000\n",
      "{'pearsonr_dev': 0.4954757192530385, 'pearsonr2_dev': 0.24549618836931583, 'pearsonr_hk': 0.5911920327510282, 'pearsonr2_hk': 0.34950801958829275, 'pearsonr': 0.5433338760020333}\n",
      "26000\n",
      "{'pearsonr_dev': 0.4936601784406935, 'pearsonr2_dev': 0.24370037177809734, 'pearsonr_hk': 0.5888197240217508, 'pearsonr2_hk': 0.34670866739705075, 'pearsonr': 0.5412399512312221}\n",
      "27000\n",
      "{'pearsonr_dev': 0.48970609312046115, 'pearsonr2_dev': 0.23981205763930577, 'pearsonr_hk': 0.5855102607848288, 'pearsonr2_hk': 0.34282226548431827, 'pearsonr': 0.537608176952645}\n",
      "28000\n",
      "{'pearsonr_dev': 0.48715832322944636, 'pearsonr2_dev': 0.23732323189172574, 'pearsonr_hk': 0.5831516738444272, 'pearsonr2_hk': 0.3400658747075572, 'pearsonr': 0.5351549985369368}\n",
      "29000\n",
      "{'pearsonr_dev': 0.48521870021021135, 'pearsonr2_dev': 0.23543718703368696, 'pearsonr_hk': 0.5799724676728187, 'pearsonr2_hk': 0.3363680632584988, 'pearsonr': 0.5325955839415151}\n",
      "30000\n",
      "{'pearsonr_dev': 0.48277583581539885, 'pearsonr2_dev': 0.23307250764725695, 'pearsonr_hk': 0.5771424723108735, 'pearsonr2_hk': 0.3330934333451073, 'pearsonr': 0.5299591540631361}\n",
      "31000\n",
      "{'pearsonr_dev': 0.4810858810112261, 'pearsonr2_dev': 0.23144362490834763, 'pearsonr_hk': 0.5746183098935069, 'pearsonr2_hk': 0.33018620206487037, 'pearsonr': 0.5278520954523666}\n",
      "32000\n",
      "{'pearsonr_dev': 0.4795691617822285, 'pearsonr2_dev': 0.2299865809325093, 'pearsonr_hk': 0.571912718594133, 'pearsonr2_hk': 0.3270841576897319, 'pearsonr': 0.5257409401881807}\n",
      "33000\n",
      "{'pearsonr_dev': 0.4775544438897187, 'pearsonr2_dev': 0.22805824687881848, 'pearsonr_hk': 0.568404671350579, 'pearsonr2_hk': 0.3230838704131598, 'pearsonr': 0.5229795576201488}\n",
      "34000\n",
      "{'pearsonr_dev': 0.47679687010390215, 'pearsonr2_dev': 0.22733525534087734, 'pearsonr_hk': 0.5648818639333852, 'pearsonr2_hk': 0.31909152020085557, 'pearsonr': 0.5208393670186438}\n",
      "35000\n",
      "{'pearsonr_dev': 0.47610302541353106, 'pearsonr2_dev': 0.2266740908079174, 'pearsonr_hk': 0.5636762840927069, 'pearsonr2_hk': 0.317730953248562, 'pearsonr': 0.519889654753119}\n",
      "36000\n",
      "{'pearsonr_dev': 0.47731027285526323, 'pearsonr2_dev': 0.22782509657316583, 'pearsonr_hk': 0.5628699203225758, 'pearsonr2_hk': 0.3168225472039428, 'pearsonr': 0.5200900965889195}\n",
      "37000\n",
      "{'pearsonr_dev': 0.4806311131149388, 'pearsonr2_dev': 0.23100626689410508, 'pearsonr_hk': 0.5629225473310489, 'pearsonr2_hk': 0.3168817942936769, 'pearsonr': 0.5217768302229938}\n",
      "38000\n",
      "{'pearsonr_dev': 0.4778351119382501, 'pearsonr2_dev': 0.22832639420104003, 'pearsonr_hk': 0.5600930285636162, 'pearsonr2_hk': 0.3137042006455638, 'pearsonr': 0.5189640702509332}\n",
      "39000\n",
      "{'pearsonr_dev': 0.47474535591083283, 'pearsonr2_dev': 0.22538315295890335, 'pearsonr_hk': 0.5577693265092668, 'pearsonr2_hk': 0.31110662159460106, 'pearsonr': 0.5162573412100498}\n",
      "40000\n",
      "{'pearsonr_dev': 0.47248231105473, 'pearsonr2_dev': 0.22323953425961862, 'pearsonr_hk': 0.5545115402525292, 'pearsonr2_hk': 0.30748304827323236, 'pearsonr': 0.5134969256536296}\n",
      "41000\n",
      "{'pearsonr_dev': 0.47033126229818933, 'pearsonr2_dev': 0.22121149629500816, 'pearsonr_hk': 0.5522187365021922, 'pearsonr2_hk': 0.3049455329440776, 'pearsonr': 0.5112749994001908}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "max_length=128\n",
    "\n",
    "with torch.no_grad():\n",
    "    state_dict='/liuzicheng/ljh/hyena-dna/weight/hyenadna/hyenadna-large-1m-seqlen'\n",
    "    hyena_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    hyena_model=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('/liuzicheng/ljh/hyena-dna/outputs/2024-05-04/13-01-30-043019/checkpoints/val/pearsonr.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.output_transform.\"\n",
    "        )\n",
    "\n",
    "    hyena_decoder = nn.Linear(256,2).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    hyena_model.load_state_dict(checkpoint,strict=False)\n",
    "    hyena_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    hyena_model.eval()\n",
    "    hyena_decoder.eval()\n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        sequence_encoded=hyena_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        hidden_states=hyena_model(input_ids=seqs).last_hidden_state\n",
    "        hidden_states=restrict(hidden_states)\n",
    "        out1=hyena_decoder(hidden_states)\n",
    "        out1_hyena=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_hyena)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list)\n",
    "        target_list_tensor=torch.FloatTensor(target_list)\n",
    "        #calculate the \n",
    "        if i>=1:\n",
    "            \n",
    "            \n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "                pearsonr=pearsonr_1(seq_list_tensor,target_list_tensor)\n",
    "                print(pearsonr)\n",
    "            \n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'pearsonr_dev': 0.41906931003452125, 'pearsonr2_dev': 0.1756190866128097, 'pearsonr_hk': 0.8753353633535679, 'pearsonr2_hk': 0.7662119983373227, 'pearsonr': 0.6472023366940446}\n",
      "2000\n",
      "{'pearsonr_dev': 0.41060924408617483, 'pearsonr2_dev': 0.1685999513290199, 'pearsonr_hk': 0.8400015690857895, 'pearsonr2_hk': 0.7056026360665884, 'pearsonr': 0.6253054065859822}\n",
      "3000\n",
      "{'pearsonr_dev': 0.6120348823835176, 'pearsonr2_dev': 0.3745866972542062, 'pearsonr_hk': 0.8317270664662886, 'pearsonr2_hk': 0.691769913092618, 'pearsonr': 0.7218809744249031}\n",
      "4000\n",
      "{'pearsonr_dev': 0.6464362819337207, 'pearsonr2_dev': 0.41787986660029286, 'pearsonr_hk': 0.8259247689789676, 'pearsonr2_hk': 0.682151724012961, 'pearsonr': 0.7361805254563442}\n",
      "5000\n",
      "{'pearsonr_dev': 0.6581854274833475, 'pearsonr2_dev': 0.43320805695143694, 'pearsonr_hk': 0.8189810741750629, 'pearsonr2_hk': 0.6707299998569399, 'pearsonr': 0.7385832508292052}\n",
      "6000\n",
      "{'pearsonr_dev': 0.6603334668402109, 'pearsonr2_dev': 0.43604028742921186, 'pearsonr_hk': 0.8108413852606853, 'pearsonr2_hk': 0.657463752051467, 'pearsonr': 0.735587426050448}\n",
      "7000\n",
      "{'pearsonr_dev': 0.6587722686249997, 'pearsonr2_dev': 0.43398090190932875, 'pearsonr_hk': 0.8045647763765317, 'pearsonr2_hk': 0.6473244793858184, 'pearsonr': 0.7316685225007658}\n",
      "8000\n",
      "{'pearsonr_dev': 0.6548988253000524, 'pearsonr2_dev': 0.4288924713793885, 'pearsonr_hk': 0.7980312846957178, 'pearsonr2_hk': 0.6368539313530979, 'pearsonr': 0.726465054997885}\n",
      "9000\n",
      "{'pearsonr_dev': 0.6526818262333063, 'pearsonr2_dev': 0.4259935662952438, 'pearsonr_hk': 0.7913890394828674, 'pearsonr2_hk': 0.6262966118136155, 'pearsonr': 0.7220354328580869}\n",
      "10000\n",
      "{'pearsonr_dev': 0.6504685082280729, 'pearsonr2_dev': 0.42310928019645455, 'pearsonr_hk': 0.7875292375350079, 'pearsonr2_hk': 0.6202022999724709, 'pearsonr': 0.7189988728815404}\n",
      "11000\n",
      "{'pearsonr_dev': 0.6475736238016413, 'pearsonr2_dev': 0.41935159824358964, 'pearsonr_hk': 0.7837326320220485, 'pearsonr2_hk': 0.6142368384962076, 'pearsonr': 0.7156531279118449}\n",
      "12000\n",
      "{'pearsonr_dev': 0.644984715889302, 'pearsonr2_dev': 0.41600528373080353, 'pearsonr_hk': 0.776483913823135, 'pearsonr2_hk': 0.6029272684260937, 'pearsonr': 0.7107343148562184}\n",
      "13000\n",
      "{'pearsonr_dev': 0.6413915974909414, 'pearsonr2_dev': 0.4113831813319818, 'pearsonr_hk': 0.7685718816263666, 'pearsonr2_hk': 0.5907027372266936, 'pearsonr': 0.704981739558654}\n",
      "14000\n",
      "{'pearsonr_dev': 0.636136564367197, 'pearsonr2_dev': 0.40466972852490096, 'pearsonr_hk': 0.7628098177571511, 'pearsonr2_hk': 0.5818788180666981, 'pearsonr': 0.6994731910621741}\n",
      "15000\n",
      "{'pearsonr_dev': 0.6400223396601711, 'pearsonr2_dev': 0.4096285952640794, 'pearsonr_hk': 0.7597258035725155, 'pearsonr2_hk': 0.5771832966139044, 'pearsonr': 0.6998740716163433}\n",
      "16000\n",
      "{'pearsonr_dev': 0.6426043291638963, 'pearsonr2_dev': 0.4129403238601812, 'pearsonr_hk': 0.7562223003850959, 'pearsonr2_hk': 0.5718721675997261, 'pearsonr': 0.6994133147744961}\n",
      "17000\n",
      "{'pearsonr_dev': 0.6383499195326221, 'pearsonr2_dev': 0.4074906197673051, 'pearsonr_hk': 0.7517874622195949, 'pearsonr2_hk': 0.5651843883505788, 'pearsonr': 0.6950686908761086}\n",
      "18000\n",
      "{'pearsonr_dev': 0.6312624694742901, 'pearsonr2_dev': 0.39849230536677904, 'pearsonr_hk': 0.7454429104954505, 'pearsonr2_hk': 0.5556851328079283, 'pearsonr': 0.6883526899848703}\n",
      "19000\n",
      "{'pearsonr_dev': 0.6245908719190963, 'pearsonr2_dev': 0.390113757284657, 'pearsonr_hk': 0.7386629716851519, 'pearsonr2_hk': 0.5456229857387396, 'pearsonr': 0.6816269218021241}\n",
      "20000\n",
      "{'pearsonr_dev': 0.6187043991051383, 'pearsonr2_dev': 0.38279513347205024, 'pearsonr_hk': 0.7327095760039031, 'pearsonr2_hk': 0.5368633227678195, 'pearsonr': 0.6757069875545207}\n",
      "21000\n",
      "{'pearsonr_dev': 0.6269788700042861, 'pearsonr2_dev': 0.3931025034318515, 'pearsonr_hk': 0.7374673099379417, 'pearsonr2_hk': 0.5438580332271042, 'pearsonr': 0.6822230899711139}\n",
      "22000\n",
      "{'pearsonr_dev': 0.64410250523441, 'pearsonr2_dev': 0.4148680372492432, 'pearsonr_hk': 0.753854473680393, 'pearsonr2_hk': 0.5682965674879424, 'pearsonr': 0.6989784894574016}\n",
      "23000\n",
      "{'pearsonr_dev': 0.6449265873168958, 'pearsonr2_dev': 0.4159303030282176, 'pearsonr_hk': 0.7651809794107138, 'pearsonr2_hk': 0.5855019312519393, 'pearsonr': 0.7050537833638049}\n",
      "24000\n",
      "{'pearsonr_dev': 0.6436892861411893, 'pearsonr2_dev': 0.4143358970929538, 'pearsonr_hk': 0.7633121758201533, 'pearsonr2_hk': 0.5826454777552966, 'pearsonr': 0.7035007309806713}\n",
      "25000\n",
      "{'pearsonr_dev': 0.6424589028076236, 'pearsonr2_dev': 0.4127534417967756, 'pearsonr_hk': 0.7617678722582069, 'pearsonr2_hk': 0.5802902912047958, 'pearsonr': 0.7021133875329153}\n",
      "26000\n",
      "{'pearsonr_dev': 0.6418925630479565, 'pearsonr2_dev': 0.4120260624962748, 'pearsonr_hk': 0.7610403111849925, 'pearsonr2_hk': 0.5791823552485502, 'pearsonr': 0.7014664371164745}\n",
      "27000\n",
      "{'pearsonr_dev': 0.6404743651351037, 'pearsonr2_dev': 0.41020741239521413, 'pearsonr_hk': 0.7588788164204868, 'pearsonr2_hk': 0.5758970580117589, 'pearsonr': 0.6996765907777953}\n",
      "28000\n",
      "{'pearsonr_dev': 0.6389520634113736, 'pearsonr2_dev': 0.4082597393376519, 'pearsonr_hk': 0.7576037740786913, 'pearsonr2_hk': 0.5739634784982767, 'pearsonr': 0.6982779187450324}\n",
      "29000\n",
      "{'pearsonr_dev': 0.6373064321065516, 'pearsonr2_dev': 0.40615948840438265, 'pearsonr_hk': 0.7559036576017452, 'pearsonr2_hk': 0.5713903395756964, 'pearsonr': 0.6966050448541483}\n",
      "30000\n",
      "{'pearsonr_dev': 0.6361476890671107, 'pearsonr2_dev': 0.4046838823054254, 'pearsonr_hk': 0.7548650455279247, 'pearsonr2_hk': 0.5698212369598757, 'pearsonr': 0.6955063672975177}\n",
      "31000\n",
      "{'pearsonr_dev': 0.6339039418135064, 'pearsonr2_dev': 0.4018342074467013, 'pearsonr_hk': 0.7536264631231251, 'pearsonr2_hk': 0.567952845919471, 'pearsonr': 0.6937652024683157}\n",
      "32000\n",
      "{'pearsonr_dev': 0.6328366112560807, 'pearsonr2_dev': 0.4004821765460798, 'pearsonr_hk': 0.7529647106860632, 'pearsonr2_hk': 0.5669558555385469, 'pearsonr': 0.692900660971072}\n",
      "33000\n",
      "{'pearsonr_dev': 0.6306459070160069, 'pearsonr2_dev': 0.397714260036042, 'pearsonr_hk': 0.7504191090529884, 'pearsonr2_hk': 0.5631288392318808, 'pearsonr': 0.6905325080344976}\n",
      "34000\n",
      "{'pearsonr_dev': 0.6291278111156096, 'pearsonr2_dev': 0.3958018027191181, 'pearsonr_hk': 0.7477337267513233, 'pearsonr2_hk': 0.5591057261214226, 'pearsonr': 0.6884307689334664}\n",
      "35000\n",
      "{'pearsonr_dev': 0.628306821809292, 'pearsonr2_dev': 0.39476946233209337, 'pearsonr_hk': 0.7459546236897981, 'pearsonr2_hk': 0.5564483006041884, 'pearsonr': 0.6871307227495451}\n",
      "36000\n",
      "{'pearsonr_dev': 0.628423015042507, 'pearsonr2_dev': 0.39491548583511493, 'pearsonr_hk': 0.7439674240705589, 'pearsonr2_hk': 0.5534875280781829, 'pearsonr': 0.686195219556533}\n",
      "37000\n",
      "{'pearsonr_dev': 0.6296753879775197, 'pearsonr2_dev': 0.3964910942246399, 'pearsonr_hk': 0.7427650907895961, 'pearsonr2_hk': 0.5516999800956769, 'pearsonr': 0.6862202393835579}\n",
      "38000\n",
      "{'pearsonr_dev': 0.6261161152996504, 'pearsonr2_dev': 0.3920213898379251, 'pearsonr_hk': 0.7394300684021557, 'pearsonr2_hk': 0.5467568260572168, 'pearsonr': 0.6827730918509031}\n",
      "39000\n",
      "{'pearsonr_dev': 0.6226513153304, 'pearsonr2_dev': 0.3876946604826772, 'pearsonr_hk': 0.736851076199276, 'pearsonr2_hk': 0.5429495084960313, 'pearsonr': 0.679751195764838}\n",
      "40000\n",
      "{'pearsonr_dev': 0.6195833536146399, 'pearsonr2_dev': 0.3838835320763639, 'pearsonr_hk': 0.7334114145074487, 'pearsonr2_hk': 0.5378923029298168, 'pearsonr': 0.6764973840610443}\n",
      "41000\n",
      "{'pearsonr_dev': 0.6174709018978582, 'pearsonr2_dev': 0.3812703146905545, 'pearsonr_hk': 0.7301969963078272, 'pearsonr2_hk': 0.533187653416973, 'pearsonr': 0.6738339491028427}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def group_by_kmer(seq: str, kmer: int) -> str:\n",
    "        return \" \".join(seq[i : i + kmer] for i in range(0, len(seq), kmer)).upper()\n",
    "max_length=128\n",
    "with torch.no_grad():\n",
    "    state_dict='/liuzicheng/ljh/hyena-dna/weight/dnabert/dnabert3/3-new-12w-0'\n",
    "    bert_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    bert_model=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('/liuzicheng/ljh/hyena-dna/outputs/2024-03-29/04-45-15-121292/checkpoints/val/pearsonr.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.output_transform.\"\n",
    "        )\n",
    "\n",
    "    bert_decoder = nn.Linear(768,2).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    bert_model.load_state_dict(checkpoint,strict=False)\n",
    "    bert_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    bert_model.eval()\n",
    "    bert_decoder.eval()\n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        all_seqs_group = group_by_kmer(all_seqs[i],kmer=3)\n",
    "        sequence_encoded=bert_tokenizer(all_seqs_group,\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        hidden_states=bert_model(input_ids=seqs).last_hidden_state\n",
    "        hidden_states=restrict(hidden_states)\n",
    "        out1=bert_decoder(hidden_states)\n",
    "        out1_bert=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_bert)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list)\n",
    "        target_list_tensor=torch.FloatTensor(target_list)\n",
    "        #calculate the \n",
    "        if i>=1:\n",
    "            \n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "                pearsonr=pearsonr_1(seq_list_tensor,target_list_tensor)\n",
    "                print(pearsonr)\n",
    "            \n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/modules/transformers_modules/dnabert2/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at /liuzicheng/ljh/hyena-dna/weight/dnabert2 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'pearsonr_dev': 0.40376231061410334, 'pearsonr2_dev': 0.16302400347243967, 'pearsonr_hk': 0.8870294712558203, 'pearsonr2_hk': 0.7868212828763802, 'pearsonr': 0.6453958909349619}\n",
      "2000\n",
      "{'pearsonr_dev': 0.38980792075562903, 'pearsonr2_dev': 0.15195021508382675, 'pearsonr_hk': 0.8537560044292595, 'pearsonr2_hk': 0.7288993150990137, 'pearsonr': 0.6217819625924442}\n",
      "3000\n",
      "{'pearsonr_dev': 0.6066960771598909, 'pearsonr2_dev': 0.3680801300412003, 'pearsonr_hk': 0.8385283466776545, 'pearsonr2_hk': 0.7031297881819608, 'pearsonr': 0.7226122119187728}\n",
      "4000\n",
      "{'pearsonr_dev': 0.6424585324177863, 'pearsonr2_dev': 0.41275296587641574, 'pearsonr_hk': 0.8311816574792742, 'pearsonr2_hk': 0.6908629477299935, 'pearsonr': 0.7368200949485302}\n",
      "5000\n",
      "{'pearsonr_dev': 0.657806057359012, 'pearsonr2_dev': 0.43270880909820775, 'pearsonr_hk': 0.8275756276598912, 'pearsonr2_hk': 0.6848814194966629, 'pearsonr': 0.7426908425094516}\n",
      "6000\n",
      "{'pearsonr_dev': 0.6589346042820474, 'pearsonr2_dev': 0.43419481272033844, 'pearsonr_hk': 0.8207012703091288, 'pearsonr2_hk': 0.6735505750870177, 'pearsonr': 0.7398179372955881}\n",
      "7000\n",
      "{'pearsonr_dev': 0.6581854100233044, 'pearsonr2_dev': 0.43320803396754537, 'pearsonr_hk': 0.8133537030369482, 'pearsonr2_hk': 0.6615442462439162, 'pearsonr': 0.7357695565301263}\n",
      "8000\n",
      "{'pearsonr_dev': 0.6559840700490895, 'pearsonr2_dev': 0.4303151001581688, 'pearsonr_hk': 0.8087745245619687, 'pearsonr2_hk': 0.6541162315804386, 'pearsonr': 0.7323792973055292}\n",
      "9000\n",
      "{'pearsonr_dev': 0.6542161683067763, 'pearsonr2_dev': 0.4279987948740003, 'pearsonr_hk': 0.8018659787306446, 'pearsonr2_hk': 0.6429890478456546, 'pearsonr': 0.7280410735187104}\n",
      "10000\n",
      "{'pearsonr_dev': 0.652359232842861, 'pearsonr2_dev': 0.42557256867532617, 'pearsonr_hk': 0.7983431838956186, 'pearsonr2_hk': 0.6373518392725935, 'pearsonr': 0.7253512083692398}\n",
      "11000\n",
      "{'pearsonr_dev': 0.6517779680573952, 'pearsonr2_dev': 0.42481451964502687, 'pearsonr_hk': 0.7933436819622668, 'pearsonr2_hk': 0.6293941977094463, 'pearsonr': 0.722560825009831}\n",
      "12000\n",
      "{'pearsonr_dev': 0.6476222143231098, 'pearsonr2_dev': 0.419414532484768, 'pearsonr_hk': 0.7862902978620601, 'pearsonr2_hk': 0.6182524325120071, 'pearsonr': 0.716956256092585}\n",
      "13000\n",
      "{'pearsonr_dev': 0.6437151767225276, 'pearsonr2_dev': 0.414369228742915, 'pearsonr_hk': 0.7756644484397045, 'pearsonr2_hk': 0.601655336573271, 'pearsonr': 0.7096898125811161}\n",
      "14000\n",
      "{'pearsonr_dev': 0.6390524381194156, 'pearsonr2_dev': 0.4083880186663695, 'pearsonr_hk': 0.7698198103862561, 'pearsonr2_hk': 0.5926225404631313, 'pearsonr': 0.7044361242528359}\n",
      "15000\n",
      "{'pearsonr_dev': 0.645047472002932, 'pearsonr2_dev': 0.41608624113737336, 'pearsonr_hk': 0.7668533957115036, 'pearsonr2_hk': 0.5880641305142639, 'pearsonr': 0.7059504338572178}\n",
      "16000\n",
      "{'pearsonr_dev': 0.6498127261026686, 'pearsonr2_dev': 0.4222565790049818, 'pearsonr_hk': 0.7631525541380961, 'pearsonr2_hk': 0.5824018208874997, 'pearsonr': 0.7064826401203823}\n",
      "17000\n",
      "{'pearsonr_dev': 0.6445910199502061, 'pearsonr2_dev': 0.415497583000447, 'pearsonr_hk': 0.7578629763607584, 'pearsonr2_hk': 0.5743562909383875, 'pearsonr': 0.7012269981554822}\n",
      "18000\n",
      "{'pearsonr_dev': 0.6372535298566945, 'pearsonr2_dev': 0.406092061314817, 'pearsonr_hk': 0.7517653789091765, 'pearsonr2_hk': 0.5651511849264577, 'pearsonr': 0.6945094543829355}\n",
      "19000\n",
      "{'pearsonr_dev': 0.630402003696159, 'pearsonr2_dev': 0.397406686264132, 'pearsonr_hk': 0.7443658636527541, 'pearsonr2_hk': 0.5540805389715106, 'pearsonr': 0.6873839336744565}\n",
      "20000\n",
      "{'pearsonr_dev': 0.624739327936674, 'pearsonr2_dev': 0.39029922787076704, 'pearsonr_hk': 0.7390318695208177, 'pearsonr2_hk': 0.5461681041674349, 'pearsonr': 0.6818855987287458}\n",
      "21000\n",
      "{'pearsonr_dev': 0.6313925606353914, 'pearsonr2_dev': 0.3986565656257164, 'pearsonr_hk': 0.7430258736138944, 'pearsonr2_hk': 0.552087448859691, 'pearsonr': 0.6872092171246429}\n",
      "22000\n",
      "{'pearsonr_dev': 0.6489436579097918, 'pearsonr2_dev': 0.42112787114134087, 'pearsonr_hk': 0.7576201668374012, 'pearsonr2_hk': 0.5739883171987316, 'pearsonr': 0.7032819123735965}\n",
      "23000\n",
      "{'pearsonr_dev': 0.6498177377248134, 'pearsonr2_dev': 0.4222630922617944, 'pearsonr_hk': 0.7695540709502244, 'pearsonr2_hk': 0.592213468116063, 'pearsonr': 0.709685904337519}\n",
      "24000\n",
      "{'pearsonr_dev': 0.6488683986983331, 'pearsonr2_dev': 0.421030198829339, 'pearsonr_hk': 0.7677351449761783, 'pearsonr2_hk': 0.5894172528315936, 'pearsonr': 0.7083017718372557}\n",
      "25000\n",
      "{'pearsonr_dev': 0.6467616095031034, 'pearsonr2_dev': 0.41830057952704475, 'pearsonr_hk': 0.7661770844082596, 'pearsonr2_hk': 0.5870273246723413, 'pearsonr': 0.7064693469556815}\n",
      "26000\n",
      "{'pearsonr_dev': 0.6462189105828614, 'pearsonr2_dev': 0.41759888039490023, 'pearsonr_hk': 0.7667600148457825, 'pearsonr2_hk': 0.5879209203663046, 'pearsonr': 0.7064894627143219}\n",
      "27000\n",
      "{'pearsonr_dev': 0.6445484387644302, 'pearsonr2_dev': 0.4154426899136645, 'pearsonr_hk': 0.764725329534792, 'pearsonr2_hk': 0.5848048296320962, 'pearsonr': 0.7046368841496111}\n",
      "28000\n",
      "{'pearsonr_dev': 0.6433074996744138, 'pearsonr2_dev': 0.4138445391373459, 'pearsonr_hk': 0.7632968448267919, 'pearsonr2_hk': 0.5826220733225357, 'pearsonr': 0.7033021722506029}\n",
      "29000\n",
      "{'pearsonr_dev': 0.6421259497769064, 'pearsonr2_dev': 0.4123257353768941, 'pearsonr_hk': 0.7614777924399428, 'pearsonr2_hk': 0.5798484283792087, 'pearsonr': 0.7018018711084246}\n",
      "30000\n",
      "{'pearsonr_dev': 0.6413099730657249, 'pearsonr2_dev': 0.4112784815535608, 'pearsonr_hk': 0.760572855372805, 'pearsonr2_hk': 0.5784710683299417, 'pearsonr': 0.7009414142192649}\n",
      "31000\n",
      "{'pearsonr_dev': 0.6395996403159102, 'pearsonr2_dev': 0.4090876998922417, 'pearsonr_hk': 0.7595796369444053, 'pearsonr2_hk': 0.5769612248605946, 'pearsonr': 0.6995896386301578}\n",
      "32000\n",
      "{'pearsonr_dev': 0.6382990278535012, 'pearsonr2_dev': 0.40742564895872474, 'pearsonr_hk': 0.7590369107953784, 'pearsonr2_hk': 0.5761370319497912, 'pearsonr': 0.6986679693244398}\n",
      "33000\n",
      "{'pearsonr_dev': 0.6358504984441549, 'pearsonr2_dev': 0.4043058563716802, 'pearsonr_hk': 0.7552591487297123, 'pearsonr2_hk': 0.5704163817399297, 'pearsonr': 0.6955548235869335}\n",
      "34000\n",
      "{'pearsonr_dev': 0.6331580771974982, 'pearsonr2_dev': 0.4008891507204331, 'pearsonr_hk': 0.7520206707534514, 'pearsonr2_hk': 0.5655350892404709, 'pearsonr': 0.6925893739754747}\n",
      "35000\n",
      "{'pearsonr_dev': 0.632423056958449, 'pearsonr2_dev': 0.39995892297266966, 'pearsonr_hk': 0.7506348680533386, 'pearsonr2_hk': 0.563452705137453, 'pearsonr': 0.6915289625058938}\n",
      "36000\n",
      "{'pearsonr_dev': 0.6336616837642632, 'pearsonr2_dev': 0.40152712947096114, 'pearsonr_hk': 0.7484743015644658, 'pearsonr2_hk': 0.560213780102415, 'pearsonr': 0.6910679926643646}\n",
      "37000\n",
      "{'pearsonr_dev': 0.6358067866815248, 'pearsonr2_dev': 0.40425026999028596, 'pearsonr_hk': 0.7468676913540727, 'pearsonr2_hk': 0.5578113483885624, 'pearsonr': 0.6913372390177988}\n",
      "38000\n",
      "{'pearsonr_dev': 0.6325625761853095, 'pearsonr2_dev': 0.40013541279019554, 'pearsonr_hk': 0.7437969744241721, 'pearsonr2_hk': 0.5532339391625526, 'pearsonr': 0.6881797753047408}\n",
      "39000\n",
      "{'pearsonr_dev': 0.6288702095191482, 'pearsonr2_dev': 0.3954777404206573, 'pearsonr_hk': 0.7407944204091456, 'pearsonr2_hk': 0.5487763733093219, 'pearsonr': 0.6848323149641469}\n",
      "40000\n",
      "{'pearsonr_dev': 0.6259142126726143, 'pearsonr2_dev': 0.3917686016255786, 'pearsonr_hk': 0.7374257677775907, 'pearsonr2_hk': 0.5437967629823691, 'pearsonr': 0.6816699902251024}\n",
      "41000\n",
      "{'pearsonr_dev': 0.6232114892718278, 'pearsonr2_dev': 0.38839256036040953, 'pearsonr_hk': 0.7347864017693169, 'pearsonr2_hk': 0.5399110562250999, 'pearsonr': 0.6789989455205723}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def group_by_kmer(seq: str, kmer: int) -> str:\n",
    "        return \" \".join(seq[i : i + kmer] for i in range(0, len(seq), kmer)).upper()\n",
    "max_length=128\n",
    "with torch.no_grad():\n",
    "    state_dict='/liuzicheng/ljh/hyena-dna/weight/dnabert2'\n",
    "    bert2_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    bert2_model=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('/liuzicheng/ljh/hyena-dna/outputs/2024-03-29/08-13-54-405523/checkpoints/val/pearsonr.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.output_transform.\"\n",
    "        )\n",
    "\n",
    "    bert2_decoder = nn.Linear(768,2).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    bert2_model.load_state_dict(checkpoint,strict=False)\n",
    "    bert2_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    bert2_model.eval()\n",
    "    bert2_decoder.eval()\n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "\n",
    "        sequence_encoded=bert2_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        hidden_states=bert2_model(input_ids=seqs,export_hidden_states=True)[0]\n",
    "        hidden_states=restrict(hidden_states)\n",
    "        out1=bert2_decoder(hidden_states)\n",
    "        out1_bert2=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_bert2)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list)\n",
    "        target_list_tensor=torch.FloatTensor(target_list)\n",
    "        #calculate the \n",
    "        if i>=1:\n",
    "            \n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "                pearsonr=pearsonr_1(seq_list_tensor,target_list_tensor)\n",
    "                print(pearsonr)\n",
    "            \n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/liuzicheng/anaconda3/envs/evo-design/lib/python3.11/site-packages/transformers/modeling_utils.py:1051: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "{'pearsonr_dev': 0.6241779409090845, 'pearsonr2_dev': 0.3895981019175046, 'pearsonr_hk': 0.7401273713593093, 'pearsonr2_hk': 0.547788525835241, 'pearsonr': 0.6821526561341968}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def group_by_kmer(seq: str, kmer: int) -> str:\n",
    "        return \" \".join(seq[i : i + kmer] for i in range(0, len(seq), kmer)).upper()\n",
    "max_length=128\n",
    "with torch.no_grad():\n",
    "    state_dict='/liuzicheng/ljh/hyena-dna/weight/genalm/gena-lm-bert-large-t2t'\n",
    "    genalm_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    genalm_model=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('/liuzicheng/ljh/hyena-dna/outputs/2024-03-30/01-49-47-161996/checkpoints/val/pearsonr.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.output_transform.\"\n",
    "        )\n",
    "\n",
    "    genalm_decoder = nn.Linear(1024,2).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    genalm_model.load_state_dict(checkpoint,strict=False)\n",
    "    genalm_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    genalm_model.eval()\n",
    "    genalm_decoder.eval()\n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "\n",
    "        sequence_encoded=genalm_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        hidden_states=genalm_model(input_ids=seqs, output_hidden_states=True,).hidden_states[-1]\n",
    "        hidden_states=restrict(hidden_states)\n",
    "        out1=genalm_decoder(hidden_states)\n",
    "        out1_genalm=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_genalm)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list)\n",
    "        target_list_tensor=torch.FloatTensor(target_list)\n",
    "        #calculate the \n",
    "        if i>=1:\n",
    "            \n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "    pearsonr=pearsonr_1(seq_list_tensor,target_list_tensor)\n",
    "    print(pearsonr)\n",
    "            \n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "{'pearsonr_dev': 0.6122770428054839, 'pearsonr2_dev': 0.37488317714662833, 'pearsonr_hk': 0.7367069263616648, 'pearsonr2_hk': 0.5427370953492514, 'pearsonr': 0.6744919845835744}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel,AutoModelForMaskedLM\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def group_by_kmer(seq: str, kmer: int) -> str:\n",
    "        return \" \".join(seq[i : i + kmer] for i in range(0, len(seq), kmer)).upper()\n",
    "max_length=128\n",
    "with torch.no_grad():\n",
    "    state_dict='/liuzicheng/ljh/hyena-dna/weight/nt/nucleotide-transformer-v2-500m-multi-species'\n",
    "    nt_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    nt_model=AutoModelForMaskedLM.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('/liuzicheng/ljh/hyena-dna/outputs/2024-03-29/10-42-51-953352/checkpoints/val/pearsonr.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.output_transform.\"\n",
    "        )\n",
    "\n",
    "    nt_decoder = nn.Linear(1024,2).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    nt_model.load_state_dict(checkpoint,strict=False)\n",
    "    nt_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    nt_model.eval()\n",
    "    nt_decoder.eval()\n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "\n",
    "        sequence_encoded=nt_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        hidden_states=nt_model(input_ids=seqs,output_hidden_states=True)['hidden_states'][-1]\n",
    "        hidden_states=restrict(hidden_states)\n",
    "        out1=nt_decoder(hidden_states)\n",
    "        out1_nt=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_nt)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list)\n",
    "        target_list_tensor=torch.FloatTensor(target_list)\n",
    "        #calculate the \n",
    "        if i>=1:\n",
    "            \n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "    pearsonr=pearsonr_1(seq_list_tensor,target_list_tensor)\n",
    "    print(pearsonr)\n",
    "            \n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "{'pearsonr_dev': 0.44316330657723835, 'pearsonr2_dev': 0.19639371629647134, 'pearsonr_hk': 0.5303301817137167, 'pearsonr2_hk': 0.28125010163650377, 'pearsonr': 0.48674674414547753}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel,AutoModelForMaskedLM\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def group_by_kmer(seq: str, kmer: int) -> str:\n",
    "        return \" \".join(seq[i : i + kmer] for i in range(0, len(seq), kmer)).upper()\n",
    "max_length=128\n",
    "with torch.no_grad():\n",
    "    state_dict='/liuzicheng/ljh/hyena-dna/weight/mamba/caduceus-ph_seqlen-131k_d_model-256_n_layer-16'\n",
    "    mamba_tokenizer=AutoTokenizer.from_pretrained(state_dict, trust_remote_code=True)\n",
    "    mamba_model=AutoModel.from_pretrained(state_dict, trust_remote_code=True).to('cuda')\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('/liuzicheng/ljh/hyena-dna/outputs/2024-04-19/14-39-48-177210/checkpoints/val/pearsonr.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"decoder.0.output_transform.\"\n",
    "        )\n",
    "\n",
    "    mamba_decoder = nn.Linear(256,2).to('cuda')\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    mamba_model.load_state_dict(checkpoint,strict=False)\n",
    "    mamba_decoder.load_state_dict(checkpoint,strict=False)\n",
    "    mamba_model.eval()\n",
    "    mamba_decoder.eval()\n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "\n",
    "        sequence_encoded=mamba_tokenizer(all_seqs[i],\n",
    "                            add_special_tokens= False,  # this is what controls adding eos\n",
    "                            padding=\"max_length\",\n",
    "                            max_length=max_length,\n",
    "                            truncation=True,\n",
    "                        )\n",
    "        seq_ids=sequence_encoded['input_ids']\n",
    "        seq_ids = torch.LongTensor(seq_ids)\n",
    "        target = all_labels[i]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        hidden_states=mamba_model(seqs,output_hidden_states=True).last_hidden_state\n",
    "        hidden_states=restrict(hidden_states)\n",
    "        out1=mamba_decoder(hidden_states)\n",
    "        out1_mamba=out1.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_mamba)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list)\n",
    "        target_list_tensor=torch.FloatTensor(target_list)\n",
    "        #calculate the \n",
    "        if i>=1:\n",
    "            \n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "    pearsonr=pearsonr_1(seq_list_tensor,target_list_tensor)\n",
    "    print(pearsonr)\n",
    "            \n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'pearsonr_dev': 0.24202421722145104, 'pearsonr2_dev': 0.058575721721656114, 'pearsonr_hk': 0.6362079135623132, 'pearsonr2_hk': 0.4047605092793118, 'pearsonr': 0.43911606539188214}\n",
      "2000\n",
      "{'pearsonr_dev': 0.19344125536819476, 'pearsonr2_dev': 0.03741951927842314, 'pearsonr_hk': 0.6061167038653557, 'pearsonr2_hk': 0.36737745870460325, 'pearsonr': 0.3997789796167752}\n",
      "3000\n",
      "{'pearsonr_dev': 0.3831511174324757, 'pearsonr2_dev': 0.1468047787897548, 'pearsonr_hk': 0.597412798440215, 'pearsonr2_hk': 0.3569020517401689, 'pearsonr': 0.4902819579363453}\n",
      "4000\n",
      "{'pearsonr_dev': 0.42583537391442033, 'pearsonr2_dev': 0.18133576567683418, 'pearsonr_hk': 0.5899780072093755, 'pearsonr2_hk': 0.34807404899074595, 'pearsonr': 0.507906690561898}\n",
      "5000\n",
      "{'pearsonr_dev': 0.43487575685905355, 'pearsonr2_dev': 0.18911692390373466, 'pearsonr_hk': 0.5858931499149908, 'pearsonr2_hk': 0.34327078311730985, 'pearsonr': 0.5103844533870221}\n",
      "6000\n",
      "{'pearsonr_dev': 0.43364567462259984, 'pearsonr2_dev': 0.18804857111888973, 'pearsonr_hk': 0.5775769088531056, 'pearsonr2_hk': 0.3335950856403087, 'pearsonr': 0.5056112917378528}\n",
      "7000\n",
      "{'pearsonr_dev': 0.43288660452232547, 'pearsonr2_dev': 0.1873908123748682, 'pearsonr_hk': 0.5717596322036868, 'pearsonr2_hk': 0.32690907701769517, 'pearsonr': 0.5023231183630061}\n",
      "8000\n",
      "{'pearsonr_dev': 0.43273685367643816, 'pearsonr2_dev': 0.18726118452978305, 'pearsonr_hk': 0.5662895555926358, 'pearsonr2_hk': 0.32068386077330496, 'pearsonr': 0.49951320463453697}\n",
      "9000\n",
      "{'pearsonr_dev': 0.4287964533040212, 'pearsonr2_dev': 0.18386639836610766, 'pearsonr_hk': 0.5602379493154357, 'pearsonr2_hk': 0.3138665598531647, 'pearsonr': 0.4945172013097284}\n",
      "10000\n",
      "{'pearsonr_dev': 0.42943411913866686, 'pearsonr2_dev': 0.1844136626804027, 'pearsonr_hk': 0.5562517041698399, 'pearsonr2_hk': 0.3094159583918511, 'pearsonr': 0.4928429116542534}\n",
      "11000\n",
      "{'pearsonr_dev': 0.42720433491495996, 'pearsonr2_dev': 0.18250354377013328, 'pearsonr_hk': 0.5500029334529984, 'pearsonr2_hk': 0.30250322680690345, 'pearsonr': 0.48860363418397923}\n",
      "12000\n",
      "{'pearsonr_dev': 0.4250662008968259, 'pearsonr2_dev': 0.18068127514486076, 'pearsonr_hk': 0.5432750330146466, 'pearsonr2_hk': 0.2951477614970654, 'pearsonr': 0.48417061695573627}\n",
      "13000\n",
      "{'pearsonr_dev': 0.42391549703971954, 'pearsonr2_dev': 0.17970434863043247, 'pearsonr_hk': 0.5353796588968154, 'pearsonr2_hk': 0.2866313791604704, 'pearsonr': 0.47964757796826746}\n",
      "14000\n",
      "{'pearsonr_dev': 0.41980231429401743, 'pearsonr2_dev': 0.176233983086613, 'pearsonr_hk': 0.5310179050902917, 'pearsonr2_hk': 0.281980015526482, 'pearsonr': 0.4754101096921546}\n",
      "15000\n",
      "{'pearsonr_dev': 0.42933923141757063, 'pearsonr2_dev': 0.18433217563423027, 'pearsonr_hk': 0.5304959575844441, 'pearsonr2_hk': 0.2814259610134363, 'pearsonr': 0.47991759450100735}\n",
      "16000\n",
      "{'pearsonr_dev': 0.4359255601033321, 'pearsonr2_dev': 0.19003109395140383, 'pearsonr_hk': 0.5307147072078899, 'pearsonr2_hk': 0.2816581004467563, 'pearsonr': 0.483320133655611}\n",
      "17000\n",
      "{'pearsonr_dev': 0.43595210823259994, 'pearsonr2_dev': 0.19005424067244853, 'pearsonr_hk': 0.5271300558148518, 'pearsonr2_hk': 0.2778660957433688, 'pearsonr': 0.4815410820237259}\n",
      "18000\n",
      "{'pearsonr_dev': 0.4310772012296182, 'pearsonr2_dev': 0.1858275534199607, 'pearsonr_hk': 0.5222536224955099, 'pearsonr2_hk': 0.27274884620968254, 'pearsonr': 0.47666541186256406}\n",
      "19000\n",
      "{'pearsonr_dev': 0.42757042228113773, 'pearsonr2_dev': 0.18281646600967044, 'pearsonr_hk': 0.5179675320310206, 'pearsonr2_hk': 0.2682903642383064, 'pearsonr': 0.4727689771560792}\n",
      "20000\n",
      "{'pearsonr_dev': 0.4232647452716051, 'pearsonr2_dev': 0.17915304458983677, 'pearsonr_hk': 0.5137113354799019, 'pearsonr2_hk': 0.2638993362005443, 'pearsonr': 0.46848804037575353}\n",
      "21000\n",
      "{'pearsonr_dev': 0.43080034994623817, 'pearsonr2_dev': 0.18558894151380126, 'pearsonr_hk': 0.5203718373916749, 'pearsonr2_hk': 0.27078684915038775, 'pearsonr': 0.47558609366895654}\n",
      "22000\n",
      "{'pearsonr_dev': 0.4509905591618363, 'pearsonr2_dev': 0.20339248445310576, 'pearsonr_hk': 0.5410777806511061, 'pearsonr2_hk': 0.2927651647143265, 'pearsonr': 0.4960341699064712}\n",
      "23000\n",
      "{'pearsonr_dev': 0.44950540597029087, 'pearsonr2_dev': 0.20205510999651602, 'pearsonr_hk': 0.5553652986943338, 'pearsonr2_hk': 0.3084306149938466, 'pearsonr': 0.5024353523323124}\n",
      "24000\n",
      "{'pearsonr_dev': 0.44669587967887486, 'pearsonr2_dev': 0.19953720892208385, 'pearsonr_hk': 0.5507815833165917, 'pearsonr2_hk': 0.3033603525207316, 'pearsonr': 0.4987387314977333}\n",
      "25000\n",
      "{'pearsonr_dev': 0.44249536262667194, 'pearsonr2_dev': 0.1958021459461099, 'pearsonr_hk': 0.5472784496661124, 'pearsonr2_hk': 0.2995137014689435, 'pearsonr': 0.4948869061463922}\n",
      "26000\n",
      "{'pearsonr_dev': 0.44093983177219126, 'pearsonr2_dev': 0.19442793524328833, 'pearsonr_hk': 0.5444383637013043, 'pearsonr2_hk': 0.29641313186975365, 'pearsonr': 0.49268909773674774}\n",
      "27000\n",
      "{'pearsonr_dev': 0.4372097632550353, 'pearsonr2_dev': 0.19115237708552402, 'pearsonr_hk': 0.540928235098664, 'pearsonr2_hk': 0.29260335552695543, 'pearsonr': 0.48906899917684965}\n",
      "28000\n",
      "{'pearsonr_dev': 0.4356435144065668, 'pearsonr2_dev': 0.18978527164450457, 'pearsonr_hk': 0.5396124125947251, 'pearsonr2_hk': 0.2911815558262999, 'pearsonr': 0.48762796350064597}\n",
      "29000\n",
      "{'pearsonr_dev': 0.4345659858888895, 'pearsonr2_dev': 0.18884759609158253, 'pearsonr_hk': 0.5374022109336986, 'pearsonr2_hk': 0.28880113631642745, 'pearsonr': 0.48598409841129403}\n",
      "30000\n",
      "{'pearsonr_dev': 0.43343770066043913, 'pearsonr2_dev': 0.18786824035380845, 'pearsonr_hk': 0.5353439475972954, 'pearsonr2_hk': 0.2865931422290558, 'pearsonr': 0.48439082412886725}\n",
      "31000\n",
      "{'pearsonr_dev': 0.43236231130915403, 'pearsonr2_dev': 0.18693716824059384, 'pearsonr_hk': 0.5333090318971813, 'pearsonr2_hk': 0.2844185235031087, 'pearsonr': 0.48283567160316765}\n",
      "32000\n",
      "{'pearsonr_dev': 0.43132216229636755, 'pearsonr2_dev': 0.18603880768801404, 'pearsonr_hk': 0.5299294191789627, 'pearsonr2_hk': 0.2808251893113528, 'pearsonr': 0.48062579073766515}\n",
      "33000\n",
      "{'pearsonr_dev': 0.4283890126945703, 'pearsonr2_dev': 0.1835171461974287, 'pearsonr_hk': 0.526346921022556, 'pearsonr2_hk': 0.27704108126992477, 'pearsonr': 0.47736796685856314}\n",
      "34000\n",
      "{'pearsonr_dev': 0.4275737190958447, 'pearsonr2_dev': 0.1828192852614523, 'pearsonr_hk': 0.5232748207925846, 'pearsonr2_hk': 0.2738165380755115, 'pearsonr': 0.4754242699442146}\n",
      "35000\n",
      "{'pearsonr_dev': 0.4279313200913137, 'pearsonr2_dev': 0.18312521471509438, 'pearsonr_hk': 0.5225434597570116, 'pearsonr2_hk': 0.27305166733482755, 'pearsonr': 0.47523738992416265}\n",
      "36000\n",
      "{'pearsonr_dev': 0.42964895620014126, 'pearsonr2_dev': 0.1845982255638709, 'pearsonr_hk': 0.5219907094970287, 'pearsonr2_hk': 0.27247430080121143, 'pearsonr': 0.475819832848585}\n",
      "37000\n",
      "{'pearsonr_dev': 0.43338461361747826, 'pearsonr2_dev': 0.18782222332037093, 'pearsonr_hk': 0.5220599180585558, 'pearsonr2_hk': 0.27254655804330596, 'pearsonr': 0.477722265838017}\n",
      "38000\n",
      "{'pearsonr_dev': 0.430826049457835, 'pearsonr2_dev': 0.18561108489144487, 'pearsonr_hk': 0.5193515085824187, 'pearsonr2_hk': 0.2697259894668342, 'pearsonr': 0.47508877902012686}\n",
      "39000\n",
      "{'pearsonr_dev': 0.42849258271057244, 'pearsonr2_dev': 0.18360589343797676, 'pearsonr_hk': 0.5178351764013098, 'pearsonr2_hk': 0.2681532699185757, 'pearsonr': 0.47316387955594114}\n",
      "40000\n",
      "{'pearsonr_dev': 0.426116517487367, 'pearsonr2_dev': 0.18157528647556156, 'pearsonr_hk': 0.5151853940000949, 'pearsonr2_hk': 0.265415990191033, 'pearsonr': 0.47065095574373095}\n",
      "41000\n",
      "{'pearsonr_dev': 0.42449095928063774, 'pearsonr2_dev': 0.18019257451099605, 'pearsonr_hk': 0.5132618555524578, 'pearsonr2_hk': 0.2634377323651521, 'pearsonr': 0.4688764074165478}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append('/liuzicheng/ljh/hyena-dna/')\n",
    "from src.models.sequence.deepSTAR import DeepSTAR\n",
    "max_length=128\n",
    "def genomic_to_one_hot(genomic_sequence):\n",
    "        mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "        one_hot = np.zeros((len(genomic_sequence), 4))\n",
    "        for i, base in enumerate(genomic_sequence):\n",
    "            if base in mapping:\n",
    "                one_hot[i, mapping[base]] = 1\n",
    "            else:\n",
    "                # ACGTN\n",
    "                one_hot[i, :] = 0.25  #  np.full((5,), 0.2) \n",
    "        return one_hot\n",
    "with torch.no_grad():\n",
    "    DeepSTAR_model=DeepSTAR(input_size=128,output_size=2)\n",
    "    full_sequence=[]\n",
    "    checkpoint=torch.load('/liuzicheng/ljh/hyena-dna/outputs/2024-05-13/09-21-43-779050/checkpoints/val/pearsonr.ckpt')['state_dict']\n",
    "    torch.nn.modules.utils.consume_prefix_in_state_dict_if_present(\n",
    "            checkpoint, \"model.backbone.\"\n",
    "        )\n",
    "    \n",
    "\n",
    "    #edit key name in hyena_decoder\n",
    "    \n",
    "    DeepSTAR_model.load_state_dict(checkpoint,strict=False)\n",
    "    DeepSTAR_model.to('cuda')\n",
    "    DeepSTAR_model.eval()\n",
    "\n",
    "    target_list=[]\n",
    "    seq_list=[]\n",
    "    for i in range(len(all_seqs)):\n",
    "        seq=genomic_to_one_hot(all_seqs[i])\n",
    "        seq_ids = torch.from_numpy(seq).float()[:max_length,:]\n",
    "        target = all_labels[i]\n",
    "        \n",
    "        seqs=torch.reshape(seq_ids,(1,max_length,-1)).to('cuda')\n",
    "        target_list.append(target)\n",
    "        hidden_states=DeepSTAR_model(seqs)\n",
    "        out1_deepstar=hidden_states.squeeze(1).squeeze(0).cpu().detach().numpy()\n",
    "        \n",
    "        seq_list.append(out1_deepstar)\n",
    "        seq_list_tensor=torch.FloatTensor(seq_list)\n",
    "        target_list_tensor=torch.FloatTensor(target_list)\n",
    "        #calculate the \n",
    "        if i>=1:\n",
    "            \n",
    "            \n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "                pearsonr=pearsonr_1(seq_list_tensor,target_list_tensor)\n",
    "                print(pearsonr)\n",
    "            \n",
    "\n",
    "#plot the bar plot of the pearsonr\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
